# -*- coding: utf-8 -*-
"""project_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vgL-t6N8l1Hw_Wgo1wsodFGyOTp0HJXE
"""

# install Kaggle
!pip install -q kaggle

from google.colab import files
files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d manjilkarki/deepfake-and-real-images

! unzip deepfake-and-real-images.zip

path_train = '/content/Dataset/Train'
path_valid = '/content/Dataset/Validation'
path_test = '/content/Dataset/Test'



import cv2
import numpy as np
from tensorflow.keras import layers
from tensorflow.keras.applications import DenseNet169
from tensorflow.keras.callbacks import Callback, ModelCheckpoint
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import metrics
import tensorflow as tf



import cv2
from PIL import Image
import scipy
import tensorflow as tf
from sklearn import metrics
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import os
import json


import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import tensorflow.keras
from tensorflow.keras import layers
from tensorflow.keras import regularizers
from tensorflow.keras.models import Model
from tensorflow.keras.applications import DenseNet169
from tensorflow.keras.layers import Lambda, concatenate
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, 
                          Dense, Flatten, Dropout)
from tensorflow.keras.layers import  Dropout , BatchNormalization , Dense



from tensorflow.keras.optimizers import RMSprop, Adam, SGD
from tensorflow.keras.callbacks import Callback , ReduceLROnPlateau , ModelCheckpoint, CSVLogger
from sklearn.metrics import cohen_kappa_score, accuracy_score
from tensorflow.keras.losses import categorical_crossentropy as logloss
from tensorflow.keras.metrics import categorical_accuracy

path_train = '/content/Dataset/Train'
path_valid = '/content/Dataset/Validation'
path_test = '/content/Dataset/Test'

bs = 64
row, col = 128,128
train_datagen = ImageDataGenerator()
training_set = train_datagen.flow_from_directory(path_train,
                                                 class_mode='binary',
                                                 shuffle=True,
                                                 target_size=(row,col),
                                                 batch_size=bs
                                                )
val_test_datagen = ImageDataGenerator()

validation_set = val_test_datagen.flow_from_directory(path_valid,
                                                      class_mode='binary',
                                                      shuffle=True,
                                                      target_size=(row,col),
                                                      batch_size=bs
                                                     ) 
test_set = val_test_datagen.flow_from_directory(path_valid,
                                                class_mode='binary',
                                                shuffle=True,
                                                target_size=(row,col),
                                                batch_size=bs
                                               )
training_set.class_indices

def build_model(pretrained):
    model = Sequential([
        pretrained,
        layers.GlobalAveragePooling2D(),
        layers.Dense(1, activation='sigmoid')
    ])
    
    model.compile(
        loss='binary_crossentropy',
        optimizer=Adam(),
        metrics=['accuracy']
    )
    
    return model

densenet = DenseNet169(
    weights=None,
    include_top=False,
    input_shape=(128,128,3)
)
model = build_model(densenet)
model.summary()

train_steps = 140002//64
valid_steps = 39428//64

history = model.fit_generator(
    training_set,
    epochs = 5,
    steps_per_epoch = train_steps,
    validation_data = validation_set,
    validation_steps = valid_steps
)

pd.DataFrame(history.history).plot()

_, accu = model.evaluate(test_set)
print('Final Test Acccuracy = {:.3f}'.format(accu*100))